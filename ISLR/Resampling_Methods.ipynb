{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Resampling Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Resampling involve repeatedly drawing samples from a training set and refitting a model\n",
    "of interest on each sample in order to obtain additional information about\n",
    "the fitted model. Such an approach may allow us to\n",
    "obtain information that would not be available from fitting the model only\n",
    "once using the original training sample. Two of the most commonly\n",
    "used resampling methods are **cross-validation** and the **bootstrap**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross-validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the absence of a very large designated test set that can be used to\n",
    "directly estimate the test error rate, a number of techniques can be used\n",
    "to estimate this quantity using the available training data. Here, we consider a class of methods that estimate the\n",
    "test error rate by holding out a subset of the training observations from the\n",
    "fitting process, and then applying the statistical learning method to those\n",
    "held out observations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Validation Set Approach"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The\n",
    "validation set approach, displayed is a very simple strategy. It involves randomly dividing the available set of observations into two parts, a training set and a validation set or hold-out set. The\n",
    "model is fit on the training set, and the fitted model is used to predict the\n",
    "responses for the observations in the validation set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Leave-One-Out Cross-Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Like the validation set approach, LOOCV involves splitting the set of\n",
    "observations into two parts. However, instead of creating two subsets of\n",
    "comparable size, a single observation $(x_1, y_1)$ is used for the validation\n",
    "set, and the remaining observations ${(x_2, y_2), \\dots , (x_n, y_n)}$ make up the\n",
    "training set. The statistical learning method is fit on the $n − 1$ training\n",
    "observations, and a prediction  $y_1$ is made for the excluded observation,\n",
    "using its value $x_1$. \n",
    "\n",
    "Even though this is unbiased for the test error (as we are conidering a single observation), it is a poor estimate\n",
    "because it is highly variable, since it is based upon a single observation\n",
    "$(x_1, y_1)$.\n",
    "\n",
    "We can repeat this process $n$ times, using different observation each time and the average of the test error rates."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### k-Fold Cross-Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An alternative to LOOCV is k-fold CV. This approach involves randomly\n",
    "k-fold CV\n",
    "dividing the set of observations into k groups, or folds, of approximately\n",
    "equal size. The first fold is treated as a validation set, and the method\n",
    "is fit on the remaining k − 1 folds. The mean squared error, $MSE_1$, is\n",
    "then computed on the observations in the held-out fold. This procedure is\n",
    "repeated k times; each time, a different group of observations is treated\n",
    "as a validation set. This process results in k estimates of the test error,\n",
    "$MSE_1, MSE_2, \\dots , MSE_k$. The k-fold CV estimate is computed by averaging\n",
    "these values."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
