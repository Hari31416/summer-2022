{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 id=\"Contents\">Contents<a href=\"#Contents\"></a></h2>\n",
    "        <ol>\n",
    "        <li><a class=\"\" href=\"#Classification\">Classification</a></li>\n",
    "<ol><li><a class=\"\" href=\"#Why-Not-Linear-Regression?\">Why Not Linear Regression?</a></li>\n",
    "<li><a class=\"\" href=\"#Logistic-Regression\">Logistic Regression</a></li>\n",
    "<ol><li><a class=\"\" href=\"#The-Logistic-Model\">The Logistic Model</a></li>\n",
    "<li><a class=\"\" href=\"#Estimating-the-Regression-Coefficients\">Estimating the Regression Coefficients</a></li>\n",
    "<li><a class=\"\" href=\"#Multiple-Logistic-Regression\">Multiple Logistic Regression</a></li>\n",
    "<li><a class=\"\" href=\"#Logistic-Regression-for-More-than-2-Response-Classes\">Logistic Regression for More than 2 Response Classes</a></li>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In case the response variable is quantitative, we can not use linear regression to make predictions. Predicting a qualitative response for an obserclassification\n",
    "vation can be referred to as classifying that observation and the process is called classification."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Why Not Linear Regression?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To see why linear regression is not the best choice for classification, let's look at a simple example. Suppose that we are trying to predict the medical condition of a patient\n",
    "in the emergency room on the basis of her symptoms. In this simplified\n",
    "example, there are three possible diagnoses: stroke, drug overdose, and\n",
    "epileptic seizure. We could consider encoding these values as a quantitative response variable, Y , as follows:\n",
    "$$\n",
    "Y = \\begin{cases}\n",
    "1 & \\text{if stroke} \\\\\n",
    "2 & \\text{drug overdose} \\\\\n",
    "3 & \\text{epileptic seizure}\n",
    "\\end{cases}\n",
    "$$\n",
    "But this does not make sense for a lot of reasons! First, this coding implies an ordering on the outcomes, putting drug overdose in\n",
    "between stroke and epileptic seizure, and insisting that the difference\n",
    "between stroke and drug overdose is the same as the difference between\n",
    "drug overdose and epileptic seizure. \n",
    "\n",
    "Second, the encoding is not unique, we can make another encoding as:\n",
    "$$\n",
    "Y = \\begin{cases}\n",
    "1 & \\text{epileptic seizure}\\\\\n",
    "2 & \\text{drug overdose} \\\\\n",
    "3 &  \\text{if stroke} \n",
    "\\end{cases}\n",
    "$$\n",
    "which will result in entirely different model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that if the outcome is binary, then these problems are not relevant and we can make a encoding like:\n",
    "$$\n",
    "Y = \\begin{cases}\n",
    "0 & \\text{if stroke} \\\\\n",
    "1 & \\text{drug overdose}\n",
    "\\end{cases}\n",
    "$$\n",
    "In this case, we can, in principle, use linear regression to predict the outcome. However, there is no guarantee that the output of the linear model will lie between 0 and 1. Due to these problems, we use other models such as logistic regression while doing classification."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rather than modeling the response Y\n",
    "directly, logistic regression models the probability that Y belongs to a particular category. For the `Default` data, logistic regression models the probability of default.\n",
    "For example, the probability of default given balance can be written as\n",
    "$$\n",
    "Pr(\\text{default} = \\text{Yes|balance})\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Logistic Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can start with a model\n",
    "$$\n",
    "p(X) = \\beta_0 + \\beta_1 X\n",
    "$$\n",
    "where $X$ is the explanatory variable and $p$ is the probability of the outcome. However, using this model, p can take any value from $-\\infty$ to $+\\infty$, which is absurd. Instead, we use a logistic function which gives output in the range $0$ to $1$. The model is:\n",
    "$$\n",
    "p(X) = \\frac{\\exp(\\beta_0+ \\beta_1 X)}{1 + \\exp(\\beta_0+ \\beta_1 X)}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">**Logit**: Logit is a function that takes the log of the probability and then divides by the log of 1 plus the log of the probability. For the model defined above, we get:\n",
    "$$\n",
    "\\log\\left(\\frac{p(X)}{1-p(X)}\\right) = \\beta_0 + \\beta_1 X\n",
    "$$\n",
    "> We see that the logistic\n",
    "log-odds\n",
    "regression model has a logit that is linear in X."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In a linear regression model, $\\beta_1$ gives the\n",
    "average change in Y associated with a one-unit increase in X. In contrast,\n",
    "in a logistic regression model, increasing X by one unit changes the log odds\n",
    "by $\\beta_1$, or equivalently it multiplies the odds by $e^{\\beta_1}$. This means that there is not a linear relationship between X and p(X)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Estimating the Regression Coefficients"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just like in linear regression, we have to calculate the coefficients $\\beta_0$ and $\\beta_1$. This may be done via least squares, however, using *maximum likelihood* estimation, is more efficient and general.\n",
    "\n",
    "The basic intuition behind using maximum likelihood\n",
    "to fit a logistic regression model is as follows: we seek estimates for $\\beta_0$ and\n",
    "$\\beta_1$ such that the predicted probability $\\hat{p}(x_i)$ of default for each individual, corresponds as closely as possible to the individualâ€™s observed\n",
    "default status. Mathematically, we need to maximize the following function:\n",
    "$$\n",
    "l(\\beta_0, \\beta_1) = \\prod_{i:y_i=1} p(x_i)\\prod_{i: y_i = 0} (1-p(x_i))\n",
    "$$\n",
    "The above function is called the *likelihood function*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">Maximum likelihood is a very general approach that is used to fit many\n",
    "of the non-linear models that we examine throughout this book. In the\n",
    "linear regression setting, the least squares approach is in fact a special case\n",
    "of maximum likelihood. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multiple Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By analogy with the extension from simple to multiple linear\n",
    "regression, we can generalize the one parameter logit function to multiple parameters as:\n",
    "$$\n",
    "\\log\\left(\\frac{p(X)}{1-p(X)}\\right) = \\beta_0 + \\beta_1 X_1 + \\cdots + \\beta_p X_p\n",
    "$$\n",
    "and hence, the probaility becomes:\n",
    "$$\n",
    "p(X) = \\frac{\\exp(\\beta_0 + \\beta_1 X_1 + \\cdots + \\beta_p X_p)}{1 + \\exp(\\beta_0 + \\beta_1 X_1 + \\cdots + \\beta_p X_p)}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just as before, we can use maximum likelihood to estimate the coefficients."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression for More than 2 Response Classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The two-class logistic regression models discussed in the previous sections have multiple-class\n",
    "extensions, but in practice they tend not to be used all that often. Instead, we use *discriminant analysis*."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
